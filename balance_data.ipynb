{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "balance_data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daniyal9538/CID/blob/master/balance_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ZO7myS-FdxgQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E6H2iO9ykt7A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# https://cloud.google.com/resource-manager/docs/creating-managing-projects\n",
        "project_id = 'test-demo-222423'\n",
        "bucket_name = 'cid_training_data'\n",
        "# Create the service client.\n",
        "from googleapiclient.discovery import build\n",
        "gcs_service = build('storage', 'v1')\n",
        "\n",
        "from apiclient.http import MediaIoBaseDownload"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cYdP4t-WoKMV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "duplication = 2\n",
        "start_file = 1\n",
        "end_file=41"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XSDZ91LQON2y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "w = [1,0,0,0,0,0,0,0,0]\n",
        "s = [0,1,0,0,0,0,0,0,0]\n",
        "a = [0,0,1,0,0,0,0,0,0]\n",
        "d = [0,0,0,1,0,0,0,0,0]\n",
        "wa = [0,0,0,0,1,0,0,0,0]\n",
        "wd = [0,0,0,0,0,1,0,0,0]\n",
        "sa = [0,0,0,0,0,0,1,0,0]\n",
        "sd = [0,0,0,0,0,0,0,1,0]\n",
        "nk = [0,0,0,0,0,0,0,0,1]"
      ]
    },
    {
      "metadata": {
        "id": "-jDmEgyNOvJd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "w=0.037610952\n",
        "\n",
        "s=0.355450237\n",
        "\n",
        "a=0.973709834\n",
        "\n",
        "d=0.972762646\n",
        "\n",
        "wa=0.421733324\n",
        "\n",
        "\n",
        "wd=0.47221785\n",
        "\n",
        "\n",
        "sa=1\n",
        "sd=1\n",
        "nk=0.031203033\n",
        "\n",
        "cp = [0]*9\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ahZkdwvOH_bs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "w=[]\n",
        "\n",
        "s=[]\n",
        "\n",
        "a=[]\n",
        "d=[]\n",
        "wa=[]\n",
        "wd=[]\n",
        "sa=[]\n",
        "sd=[]\n",
        "nk=[]\n",
        "cp = [w, s, a, d, wa, wd, sa, sd, nk]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O_DswAOVHfdu",
        "colab_type": "code",
        "outputId": "955c393c-5b59-4f8a-e692-5579e30e9efe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(start_file, end_file+1):\n",
        "\n",
        "  try:\n",
        "    download_name = \"training_data-{}.npy\".format(i)\n",
        "    path_name = \"mod_cid_data/mod_data-160-120-{}.npy\".format(i)\n",
        "    #new_name = \"mod_data-160-120-{}.npy\".format(i)\n",
        "    \n",
        "    with open(download_name, 'wb') as f:\n",
        "      # Download the file from a given Google Cloud Storage bucket.\n",
        "      request = gcs_service.objects().get_media(bucket=bucket_name,\n",
        "                                                    object=path_name)\n",
        "      media = MediaIoBaseDownload(f, request)\n",
        "\n",
        "      done = False\n",
        "      while not done:\n",
        "            # _ is a placeholder for a progress object that we ignore.\n",
        "            # (Our file is small, so we skip reporting progress.)\n",
        "        _, done = media.next_chunk()  \n",
        "      print(download_name, 'download complete')\n",
        "\n",
        "  except Exception as ex:\n",
        "    print('download failed', download_name, ex)\n",
        "      \n",
        " \n",
        "    \n",
        "  \n",
        "  data = np.load(download_name)\n",
        "  for x in data:\n",
        "    dp = np.argmax(x[1])\n",
        "    cp[dp].append(x)\n",
        "  !rm -rf $download_name    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training_data-1.npy download complete\n",
            "training_data-2.npy download complete\n",
            "training_data-3.npy download complete\n",
            "training_data-4.npy download complete\n",
            "training_data-5.npy download complete\n",
            "training_data-6.npy download complete\n",
            "training_data-7.npy download complete\n",
            "training_data-8.npy download complete\n",
            "training_data-9.npy download complete\n",
            "training_data-10.npy download complete\n",
            "training_data-11.npy download complete\n",
            "training_data-12.npy download complete\n",
            "training_data-13.npy download complete\n",
            "training_data-14.npy download complete\n",
            "training_data-15.npy download complete\n",
            "training_data-16.npy download complete\n",
            "training_data-17.npy download complete\n",
            "training_data-18.npy download complete\n",
            "training_data-19.npy download complete\n",
            "training_data-20.npy download complete\n",
            "training_data-21.npy download complete\n",
            "training_data-22.npy download complete\n",
            "training_data-23.npy download complete\n",
            "training_data-24.npy download complete\n",
            "training_data-25.npy download complete\n",
            "training_data-26.npy download complete\n",
            "training_data-27.npy download complete\n",
            "training_data-28.npy download complete\n",
            "training_data-29.npy download complete\n",
            "training_data-30.npy download complete\n",
            "training_data-31.npy download complete\n",
            "training_data-32.npy download complete\n",
            "training_data-33.npy download complete\n",
            "training_data-34.npy download complete\n",
            "training_data-35.npy download complete\n",
            "training_data-36.npy download complete\n",
            "training_data-37.npy download complete\n",
            "training_data-38.npy download complete\n",
            "training_data-39.npy download complete\n",
            "training_data-40.npy download complete\n",
            "training_data-41.npy download complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Tf-Np9WSC7vz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for da in cp:  \n",
        "  for x in da:\n",
        "    t=np.argmax(x[1])\n",
        "    if (t==6 or t==7):\n",
        "      s.append(x)\n",
        "    if(t==4):\n",
        "      a.append(x)\n",
        "    if(t==5):\n",
        "      d.append(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e_8Ud9q-L8AY",
        "colab_type": "code",
        "outputId": "8a585625-389a-4d8d-db08-4ad2e7d60669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "cell_type": "code",
      "source": [
        "for da in cp:\n",
        "  np.random.shuffle(da)\n",
        "for da in cp:\n",
        "  print(len(da))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "159528\n",
            "18920\n",
            "20389\n",
            "18874\n",
            "14227\n",
            "12706\n",
            "1047\n",
            "993\n",
            "192289\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oudFgiKlUFDm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataLength= [0]*9\n",
        "temp_data = []\n",
        "count = [0]*9\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "myPzg2mjFZxe",
        "colab_type": "code",
        "outputId": "13b98c4a-1bb0-419d-f206-418351a50720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "amount = 18874\n",
        "temp_data = []\n",
        "count = [0]*9\n",
        "print(temp_data, count)\n",
        "temp_data = w[0:amount]+s[0:amount]+a[0:amount]+d+nk[0:amount]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[] [0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4IqnZUx-0CYM",
        "colab_type": "code",
        "outputId": "bf003b78-fc85-4397-c0bd-0bd3c2171c26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "for x1 in temp_data:\n",
        "  l = np.argmax(x1[1])\n",
        "  count[l]+=1\n",
        "print(count)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[18874, 16839, 5700, 6168, 13174, 12706, 1044, 991, 18874]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nG8Na9yY0oXD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "new_data=[]\n",
        "for x in temp_data:\n",
        "  temp=[0]*5\n",
        "  t = np.argmax(x[1])\n",
        "  if(t==6 or t==7):\n",
        "    temp[1]=1\n",
        "  elif(t==4):\n",
        "    temp[2]=1\n",
        "  elif(t==5):\n",
        "    temp[3]=1\n",
        "  elif (t==8):\n",
        "    temp[4]=1\n",
        "  else:\n",
        "    temp[t]=1\n",
        "  new_data.append([x[0], temp])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1oR8PAFx1kzl",
        "colab_type": "code",
        "outputId": "e6a9d66f-b6c5-41bf-9cd5-9a6638a4af60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "count=[0]*5\n",
        "np.random.shuffle(new_data)\n",
        "for x in new_data:\n",
        "  l = np.argmax(x[1])\n",
        "  count[l]+=1\n",
        "print(count)\n",
        "\n",
        "i=19000\n",
        "print(new_data[i][1])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[18874, 18874, 18874, 18874, 18874]\n",
            "[1, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6ll4FSK7ZH5T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "temp_data.clear()\n",
        "cp.clear()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j2xwMqILRzKD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "amount = 9437\n",
        "initial=0\n",
        "for i in range(1, 11):\n",
        "  name=\"balanced_data-mod-5-{}.npy\".format(i)\n",
        "  data=[]\n",
        "  data=new_data[initial:amount]\n",
        "  initial+=amount\n",
        "  amount+=amount\n",
        "  np.random.shuffle(data)\n",
        "  np.save(name, data)\n",
        "  !gsutil cp $name gs://{bucket_name}/balanced_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sNhnV6qX3LZn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "name = \"balanced_data-mod1-5-1.npy\"\n",
        "np.random.shuffle(new_data)\n",
        "np.save(name, new_data)\n",
        "!gsutil cp $name gs://{bucket_name}/balanced_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jqkln8s5GOJ-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "count=[0]*9\n",
        "np.random.shuffle(temp_data)\n",
        "for i in temp_data:\n",
        "  t=np.argmax(i[1])\n",
        "  count[t]+=1\n",
        "print(count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p2T5STQjGhIw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "name =\"balanced_data-simplified-7-1.npy\"\n",
        "np.random.shuffle(temp_data)\n",
        "np.save(name, temp_data)\n",
        "!gsutil cp $name gs://{bucket_name}/balanced_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MtDmXG5QT4cu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for x in cp:\n",
        "  np.random.shuffle(x)\n",
        "for i in range (1, 4):\n",
        "  name = \"balanced_data-simplified-7-{}.npy\".format(i)\n",
        "  count = [0]*9\n",
        "  amount = 2054\n",
        "  for x in range(dataLength[0], dataLength[0]+amount):\n",
        "    temp_data.append([w[x][0],w[x][1]])\n",
        "    count[0]+=1\n",
        "  dataLength[0]+=amount\n",
        "  \n",
        "  for x in range(dataLength[1], dataLength[1]+amount):\n",
        "    temp_data.append([s[x][0],s[x][1]])\n",
        "    count[1]+=1\n",
        "  dataLength[1]+=amount\n",
        "  \n",
        "  for x in range(dataLength[2], dataLength[2]+amount):\n",
        "    temp_data.append([a[x][0],a[x][1]])\n",
        "    count[2]+=1\n",
        "  dataLength[2]+=amount\n",
        "  \n",
        "  for x in range(dataLength[3], dataLength[3]+amount):\n",
        "    temp_data.append([d[x][0],d[x][1]])\n",
        "    count[3]+=1\n",
        "  dataLength[3]+=amount\n",
        "  \n",
        "  for x in range(dataLength[4], dataLength[4]+amount):\n",
        "    temp_data.append([wa[x][0],wa[x][1]])\n",
        "    count[4]+=1\n",
        "  dataLength[4]+=amount\n",
        "  \n",
        "  for x in range(dataLength[5], dataLength[5]+amount):\n",
        "    temp_data.append([wd[x][0],wd[x][1]])\n",
        "    count[5]+=1\n",
        "  dataLength[5]+=amount\n",
        "  \n",
        "  for x in range(0, len(sa)-1):\n",
        "    pass\n",
        "    #temp_data.append([sa[x][0],sa[x][1]])\n",
        "    #count[6]+=1\n",
        "  #dataLength[6]+=1111\n",
        "  \n",
        "  for x in range(0, len(sd)-1):\n",
        "    pass\n",
        "    #temp_data.append([sd[x][0],sd[x][1]])\n",
        "    #count[7]+=1\n",
        "  #dataLength[7]+=1111\n",
        "  \n",
        "  for x in range(dataLength[8], dataLength[8]+amount):\n",
        "    temp_data.append([nk[x][0],nk[x][1]])\n",
        "    count[8]+=1\n",
        "  dataLength[8]+=amount\n",
        " \n",
        "  print(count)\n",
        "  count.clear()\n",
        "  count=[0]*9\n",
        "  np.random.shuffle(temp_data)\n",
        "  for x in temp_data:\n",
        "    l = np.argmax(x[1])\n",
        "    count[l]+=1\n",
        "  print(count)\n",
        "  print(dataLength)\n",
        "  sum = 0\n",
        "  for x in count:\n",
        "    sum+=x\n",
        "  print(sum)\n",
        "  np.random.shuffle(temp_data)\n",
        "  np.save(name, temp_data)\n",
        "  !gsutil cp $name gs://{bucket_name}/balanced_data\n",
        "  temp_data.clear()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9102GBsteUAy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for l in temp_data:\n",
        "  print(l)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "evYoN9PaoSse",
        "colab_type": "code",
        "outputId": "7e184c01-8f7b-4e58-cfe9-6f88024a6303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2897
        }
      },
      "cell_type": "code",
      "source": [
        "count = 1\n",
        "new_data=[]\n",
        "temp_data=[]\n",
        "new_data.clear()\n",
        "for i in range(start_file, end_file+1):\n",
        "  print(i)\n",
        "  try:\n",
        "    download_name = \"training_data-{}.npy\".format(i)\n",
        "    path_name = \"mod_cid_data/mod_data-160-120-{}.npy\".format(i)\n",
        "    #new_name = \"mod_data-160-120-{}.npy\".format(i)\n",
        "    \n",
        "    with open(download_name, 'wb') as f:\n",
        "      # Download the file from a given Google Cloud Storage bucket.\n",
        "      request = gcs_service.objects().get_media(bucket=bucket_name,\n",
        "                                                    object=path_name)\n",
        "      media = MediaIoBaseDownload(f, request)\n",
        "\n",
        "      done = False\n",
        "      while not done:\n",
        "            # _ is a placeholder for a progress object that we ignore.\n",
        "            # (Our file is small, so we skip reporting progress.)\n",
        "        _, done = media.next_chunk()  \n",
        "      print(download_name, 'download complete')\n",
        "      \n",
        "  except Exception as ex:\n",
        "    print(\"Download failed file\", download_name, ex)\n",
        "  \n",
        "  \n",
        "  try:\n",
        "    data = np.load(download_name)\n",
        "    \n",
        "    #np.random.shuffle(data)\n",
        "    #tempCount=[0]*9\n",
        "    r=np.random.uniform(0,1)\n",
        "    for x in data:\n",
        "      dp = np.argmax(x[1])\n",
        "      if(dp==0):\n",
        "        if(r<=w):\n",
        "          new_data.append(x)\n",
        "          cp[dp]+=1\n",
        "      if(dp==1):\n",
        "        if(r<=s):\n",
        "          new_data.append(x)\n",
        "          cp[dp]+=1\n",
        "      if(dp==2):\n",
        "        if(r<=a):\n",
        "          new_data.append(x)\n",
        "          cp[dp]+=1\n",
        "      if(dp==3):\n",
        "        if(r<=d):\n",
        "          new_data.append(x)\n",
        "          cp[dp]+=1\n",
        "      if(dp==4):\n",
        "        if(r<=wa):\n",
        "          new_data.append(x)\n",
        "          cp[dp]+=1\n",
        "      if(dp==5):\n",
        "        if(r<=wd):\n",
        "          new_data.append(x)\n",
        "          cp[dp]+=1\n",
        "      if(dp==6):\n",
        "        if(r<=sa):\n",
        "          new_data.append(x)\n",
        "          new_data.append(x)\n",
        "          new_data.append(x)\n",
        "          new_data.append(x)\n",
        "          new_data.append(x)\n",
        "          new_data.append(x)\n",
        "          cp[dp]+=6\n",
        "      if(dp==7):\n",
        "        if(r<=sd):\n",
        "          new_data.append(x)\n",
        "          new_data.append(x)\n",
        "          new_data.append(x)\n",
        "          new_data.append(x)\n",
        "          new_data.append(x)\n",
        "          new_data.append(x)\n",
        "          cp[dp]+=6\n",
        "      if(dp==8):\n",
        "        if(r<=nk):\n",
        "          new_data.append(x)\n",
        "          cp[dp]+=1\n",
        "      \n",
        "      \n",
        "      if(len(new_data)>=10000):\n",
        "        name = \"balanced_data-{}.npy\".format(count)\n",
        "        np.random.shuffle(new_data)\n",
        "        np.save(name, new_data)\n",
        "        !gsutil cp $name gs://{bucket_name}/balanced_data\n",
        "          \n",
        "        !rm -rf $name\n",
        "        temp_data=new_data\n",
        "        new_data.clear()\n",
        "    \n",
        "        \n",
        "        count+=1\n",
        "        print(name, \"saved\")\n",
        "      \n",
        "    !rm -rf $download_name\n",
        "  except Exception as ex:\n",
        "    print(ex)\n",
        "    \n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "training_data-1.npy download complete\n",
            "2\n",
            "training_data-2.npy download complete\n",
            "3\n",
            "training_data-3.npy download complete\n",
            "4\n",
            "training_data-4.npy download complete\n",
            "5\n",
            "training_data-5.npy download complete\n",
            "6\n",
            "training_data-6.npy download complete\n",
            "7\n",
            "training_data-7.npy download complete\n",
            "8\n",
            "training_data-8.npy download complete\n",
            "9\n",
            "training_data-9.npy download complete\n",
            "Copying file://balanced_data-1.npy [Content-Type=application/octet-stream]...\n",
            "==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "/\n",
            "Operation completed over 1 objects/188.3 MiB.                                    \n",
            "balanced_data-1.npy saved\n",
            "10\n",
            "training_data-10.npy download complete\n",
            "11\n",
            "training_data-11.npy download complete\n",
            "12\n",
            "training_data-12.npy download complete\n",
            "13\n",
            "training_data-13.npy download complete\n",
            "14\n",
            "training_data-14.npy download complete\n",
            "15\n",
            "training_data-15.npy download complete\n",
            "16\n",
            "training_data-16.npy download complete\n",
            "17\n",
            "training_data-17.npy download complete\n",
            "18\n",
            "training_data-18.npy download complete\n",
            "Copying file://balanced_data-2.npy [Content-Type=application/octet-stream]...\n",
            "==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "/\n",
            "Operation completed over 1 objects/203.1 MiB.                                    \n",
            "balanced_data-2.npy saved\n",
            "19\n",
            "training_data-19.npy download complete\n",
            "Copying file://balanced_data-3.npy [Content-Type=application/octet-stream]...\n",
            "==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "/\n",
            "Operation completed over 1 objects/279.1 MiB.                                    \n",
            "balanced_data-3.npy saved\n",
            "20\n",
            "training_data-20.npy download complete\n",
            "21\n",
            "training_data-21.npy download complete\n",
            "22\n",
            "training_data-22.npy download complete\n",
            "23\n",
            "training_data-23.npy download complete\n",
            "24\n",
            "training_data-24.npy download complete\n",
            "25\n",
            "training_data-25.npy download complete\n",
            "26\n",
            "training_data-26.npy download complete\n",
            "27\n",
            "training_data-27.npy download complete\n",
            "28\n",
            "training_data-28.npy download complete\n",
            "29\n",
            "training_data-29.npy download complete\n",
            "30\n",
            "training_data-30.npy download complete\n",
            "31\n",
            "training_data-31.npy download complete\n",
            "32\n",
            "training_data-32.npy download complete\n",
            "Copying file://balanced_data-4.npy [Content-Type=application/octet-stream]...\n",
            "==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "-\n",
            "Operation completed over 1 objects/257.1 MiB.                                    \n",
            "balanced_data-4.npy saved\n",
            "33\n",
            "training_data-33.npy download complete\n",
            "34\n",
            "training_data-34.npy download complete\n",
            "35\n",
            "training_data-35.npy download complete\n",
            "36\n",
            "training_data-36.npy download complete\n",
            "37\n",
            "training_data-37.npy download complete\n",
            "38\n",
            "training_data-38.npy download complete\n",
            "Copying file://balanced_data-5.npy [Content-Type=application/octet-stream]...\n",
            "==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "/\n",
            "Operation completed over 1 objects/171.4 MiB.                                    \n",
            "balanced_data-5.npy saved\n",
            "39\n",
            "training_data-39.npy download complete\n",
            "40\n",
            "training_data-40.npy download complete\n",
            "41\n",
            "training_data-41.npy download complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2PK_RrpyiBwM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "while(True):\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-0C3dI3_R4lj",
        "colab_type": "code",
        "outputId": "0b9ed61d-dcee-4ed0-c255-c9e422986d60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(new_data))\n",
        "print(cp, count)\n",
        "name = \"balanaced_data-{}.npy\".format(count)\n",
        "np.random.shuffle(new_data)\n",
        "np.save(name, new_data)\n",
        "!gsutil cp $name gs://{bucket_name}/balanced_data\n",
        "          \n",
        "!rm -rf $name"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4688\n",
            "[3957, 7741, 6027, 6029, 6923, 7135, 6282, 5958, 4636] 6\n",
            "Copying file://balanaced_data-6.npy [Content-Type=application/octet-stream]...\n",
            "|\n",
            "Operation completed over 1 objects/98.3 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}